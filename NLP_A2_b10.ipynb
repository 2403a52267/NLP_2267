{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPr7ZhOH3sosip6CTKth7Us",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2403a52267/NLP_2267/blob/main/NLP_A2_b10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk spacy\n",
        "!python -m spacy download en_core_web_sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rdhfN5do_EaI",
        "outputId": "b4c547be-1dcc-45be-bdba-64dbb93638b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.12/dist-packages (3.8.11)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2025.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.15)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.13)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (8.3.10)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.5.2)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.4.3)\n",
            "Requirement already satisfied: typer-slim<1.0.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.20.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.32.4)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.12.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.41.4)\n",
            "Requirement already satisfied: typing-extensions>=4.14.1 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.11.12)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.3)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy) (0.23.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy) (7.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->spacy) (3.0.3)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.4.2->spacy) (2.0.1)\n",
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m97.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import spacy\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.stem import PorterStemmer"
      ],
      "metadata": {
        "id": "dO4HtjcH_OVY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_HB-rdt2_V5q",
        "outputId": "1029f9d9-2b1f-42a8-c4dd-03b221b97b09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "medical_text = \"\"\"\n",
        "Hypertension is a chronic medical condition characterized by elevated blood pressure.\n",
        "Patients with persistent hypertension are at increased risk of cardiovascular disease,\n",
        "stroke, and kidney failure. Lifestyle modifications such as reduced salt intake,\n",
        "regular physical activity, and medication adherence are essential for effective management.\n",
        "Early diagnosis and continuous monitoring significantly improve patient outcomes.\n",
        "\"\""
      ],
      "metadata": {
        "id": "4v9ftR2Z_rHU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "SENTENCE TOKENIZATION USING NLTK\n",
        "sentences = sent_tokenize(medical_text)\n",
        "print(\"Sentence Tokenization:\")\n",
        "for s in sentences:\n",
        "print(\"-\", s)"
      ],
      "metadata": {
        "id": "adouJMTM_wRX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sentence Tokenization:-\n",
        "Hypertension is a chronic medical condition characterized by elevated blood pressure.- Patients with persistent hypertension are at increased risk of cardiovascular disease,\n",
        "stroke, and kidney failure.- Lifestyle modifications such as reduced salt intake,\n",
        "regular physical activity, and medication adherence are essential for effective management.- Early diagnosis and continuous monitoring significantly improve patient outcom"
      ],
      "metadata": {
        "id": "RbKx_GeJ_yga"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "WORD TOKENIZATION USING NLTL"
      ],
      "metadata": {
        "id": "6Ax5LFt6AR2F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "medical_text = \"\"\"\n",
        "Hypertension is a chronic medical condition characterized by elevated blood pressure.\n",
        "Patients with persistent hypertension are at increased risk of cardiovascular disease,\n",
        "stroke, and kidney failure. Lifestyle modifications such as reduced salt intake,\n",
        "regular physical activity, and medication adherence are essential for effective management.\n",
        "Early diagnosis and continuous monitoring significantly improve patient outcomes.\n",
        "\"\"\"\n",
        "\n",
        "words = word_tokenize(medical_text)\n",
        "print(\"\\nWord Tokenization:\")\n",
        "print(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZA0aRO1_2Te",
        "outputId": "8fac8920-647f-4de5-8664-ac5e9151d9a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Word Tokenization:\n",
            "['Hypertension', 'is', 'a', 'chronic', 'medical', 'condition', 'characterized', 'by', 'elevated', 'blood', 'pressure', '.', 'Patients', 'with', 'persistent', 'hypertension', 'are', 'at', 'increased', 'risk', 'of', 'cardiovascular', 'disease', ',', 'stroke', ',', 'and', 'kidney', 'failure', '.', 'Lifestyle', 'modifications', 'such', 'as', 'reduced', 'salt', 'intake', ',', 'regular', 'physical', 'activity', ',', 'and', 'medication', 'adherence', 'are', 'essential', 'for', 'effective', 'management', '.', 'Early', 'diagnosis', 'and', 'continuous', 'monitoring', 'significantly', 'improve', 'patient', 'outcomes', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LEMMATIZATION USING spaCY"
      ],
      "metadata": {
        "id": "4QCWNTL3AiOx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(medical_text)\n",
        "lemmatized_words = [token.lemma_ for token in doc if token.is_alpha]\n",
        "print(\"Lemmatized Words:\")\n",
        "print(lemmatized_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r06sj257ATXU",
        "outputId": "fee53b5d-a929-4a23-fa5f-c568dd59f7f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lemmatized Words:\n",
            "['Hypertension', 'be', 'a', 'chronic', 'medical', 'condition', 'characterize', 'by', 'elevated', 'blood', 'pressure', 'patient', 'with', 'persistent', 'hypertension', 'be', 'at', 'increase', 'risk', 'of', 'cardiovascular', 'disease', 'stroke', 'and', 'kidney', 'failure', 'lifestyle', 'modification', 'such', 'as', 'reduce', 'salt', 'intake', 'regular', 'physical', 'activity', 'and', 'medication', 'adherence', 'be', 'essential', 'for', 'effective', 'management', 'early', 'diagnosis', 'and', 'continuous', 'monitoring', 'significantly', 'improve', 'patient', 'outcome']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "COMPARISION : ORIGINALvs STEMMED vs LEMMATIZED"
      ],
      "metadata": {
        "id": "ZTk1PGpAAvOW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "ps = PorterStemmer()\n",
        "comparison = []\n",
        "for word in words:\n",
        "    if word.isalpha():\n",
        "        stem = ps.stem(word)\n",
        "        lemma = nlp(word)[0].lemma_\n",
        "        comparison.append((word, stem, lemma))\n",
        "comparison[:15]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOMui33XAv_S",
        "outputId": "b890fde6-11bf-4112-f702-d17da3b3518d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Hypertension', 'hypertens', 'hypertension'),\n",
              " ('is', 'is', 'be'),\n",
              " ('a', 'a', 'a'),\n",
              " ('chronic', 'chronic', 'chronic'),\n",
              " ('medical', 'medic', 'medical'),\n",
              " ('condition', 'condit', 'condition'),\n",
              " ('characterized', 'character', 'characterize'),\n",
              " ('by', 'by', 'by'),\n",
              " ('elevated', 'elev', 'elevate'),\n",
              " ('blood', 'blood', 'blood'),\n",
              " ('pressure', 'pressur', 'pressure'),\n",
              " ('Patients', 'patient', 'patient'),\n",
              " ('with', 'with', 'with'),\n",
              " ('persistent', 'persist', 'persistent'),\n",
              " ('hypertension', 'hypertens', 'hypertension')]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SRUniversity=\"\"\"The SR University campus is located in Ananthasagar village of Hasanparthy Mandal in Warangal, Telan\n",
        "It is in 150 acres, with both separate hostel facilities for boys and girls.\n",
        "There is a huge central library along with Indias largest Technology Business Incubator (TBI) in tier 2 cities.\"\"\""
      ],
      "metadata": {
        "id": "_IUOPnupB6PB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "SRUniversity\n",
        "'\n",
        "The SR University campus is located in Ananthasagar village of Hasanparthy Mandal in Warangal, Telangana, India. \\nI\n",
        "t is in 150 acres, with both separate hostel facilities for boys and girls. \\nThere is a huge central library along w\n"
      ],
      "metadata": {
        "id": "BpIAnpYkB7Mx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "SRUniversity=\"\"\"The SR University campus is located in Ananthasagar village of Hasanparthy Mandal in Warangal, Telan\n",
        "It is in 150 acres, with both separate hostel facilities for boys and girls.\n",
        "There is a huge central library along with Indias largest Technology Business Incubator (TBI) in tier 2 cities.\"\"\"\n",
        "\n",
        "word_tokenize(SRUniversity)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "giZV_TrVCJ3P",
        "outputId": "312b0007-ec0f-4ffb-a15c-1e4dc90c077a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The',\n",
              " 'SR',\n",
              " 'University',\n",
              " 'campus',\n",
              " 'is',\n",
              " 'located',\n",
              " 'in',\n",
              " 'Ananthasagar',\n",
              " 'village',\n",
              " 'of',\n",
              " 'Hasanparthy',\n",
              " 'Mandal',\n",
              " 'in',\n",
              " 'Warangal',\n",
              " ',',\n",
              " 'Telan',\n",
              " 'It',\n",
              " 'is',\n",
              " 'in',\n",
              " '150',\n",
              " 'acres',\n",
              " ',',\n",
              " 'with',\n",
              " 'both',\n",
              " 'separate',\n",
              " 'hostel',\n",
              " 'facilities',\n",
              " 'for',\n",
              " 'boys',\n",
              " 'and',\n",
              " 'girls',\n",
              " '.',\n",
              " 'There',\n",
              " 'is',\n",
              " 'a',\n",
              " 'huge',\n",
              " 'central',\n",
              " 'library',\n",
              " 'along',\n",
              " 'with',\n",
              " 'Indias',\n",
              " 'largest',\n",
              " 'Technology',\n",
              " 'Business',\n",
              " 'Incubator',\n",
              " '(',\n",
              " 'TBI',\n",
              " ')',\n",
              " 'in',\n",
              " 'tier',\n",
              " '2',\n",
              " 'cities',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "sent_tokenize(SRUniversity)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VfgyN6EhCdBw",
        "outputId": "535edb65-35a2-4f25-c239-d7721272fe24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The SR University campus is located in Ananthasagar village of Hasanparthy Mandal in Warangal, Telan\\nIt is in 150 acres, with both separate hostel facilities for boys and girls.',\n",
              " 'There is a huge central library along with Indias largest Technology Business Incubator (TBI) in tier 2 cities.']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download(\"stopwords\")\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i79AvnkVCn0b",
        "outputId": "2fbe23f9-33e0-49cc-b37f-2b1a75fa073f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words_in_quote = word_tokenize(SRUniversity)\n",
        "words_in_quote"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCWxR7HzCuuX",
        "outputId": "0ebcde36-4aa0-41d8-b218-646f60735780"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The',\n",
              " 'SR',\n",
              " 'University',\n",
              " 'campus',\n",
              " 'is',\n",
              " 'located',\n",
              " 'in',\n",
              " 'Ananthasagar',\n",
              " 'village',\n",
              " 'of',\n",
              " 'Hasanparthy',\n",
              " 'Mandal',\n",
              " 'in',\n",
              " 'Warangal',\n",
              " ',',\n",
              " 'Telan',\n",
              " 'It',\n",
              " 'is',\n",
              " 'in',\n",
              " '150',\n",
              " 'acres',\n",
              " ',',\n",
              " 'with',\n",
              " 'both',\n",
              " 'separate',\n",
              " 'hostel',\n",
              " 'facilities',\n",
              " 'for',\n",
              " 'boys',\n",
              " 'and',\n",
              " 'girls',\n",
              " '.',\n",
              " 'There',\n",
              " 'is',\n",
              " 'a',\n",
              " 'huge',\n",
              " 'central',\n",
              " 'library',\n",
              " 'along',\n",
              " 'with',\n",
              " 'Indias',\n",
              " 'largest',\n",
              " 'Technology',\n",
              " 'Business',\n",
              " 'Incubator',\n",
              " '(',\n",
              " 'TBI',\n",
              " ')',\n",
              " 'in',\n",
              " 'tier',\n",
              " '2',\n",
              " 'cities',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words(\"english\"))\n",
        "filtered_list = []\n",
        "for word in words_in_quote:\n",
        "    if word.casefold() not in stop_words:\n",
        "        filtered_list.append(word)\n",
        "print(filtered_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hkvd0wESC13Y",
        "outputId": "b67689e8-c048-4a6a-aa9c-0a89356c7862"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['SR', 'University', 'campus', 'located', 'Ananthasagar', 'village', 'Hasanparthy', 'Mandal', 'Warangal', ',', 'Telan', '150', 'acres', ',', 'separate', 'hostel', 'facilities', 'boys', 'girls', '.', 'huge', 'central', 'library', 'along', 'Indias', 'largest', 'Technology', 'Business', 'Incubator', '(', 'TBI', ')', 'tier', '2', 'cities', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "words = word_tokenize(SRUniversity)\n",
        "for word in words:\n",
        "    print(word,\"--->\",lemmatizer.lemmatize(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQErN00BDAVw",
        "outputId": "ea396426-df6b-4190-e14b-36f5d30d5b7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The ---> The\n",
            "SR ---> SR\n",
            "University ---> University\n",
            "campus ---> campus\n",
            "is ---> is\n",
            "located ---> located\n",
            "in ---> in\n",
            "Ananthasagar ---> Ananthasagar\n",
            "village ---> village\n",
            "of ---> of\n",
            "Hasanparthy ---> Hasanparthy\n",
            "Mandal ---> Mandal\n",
            "in ---> in\n",
            "Warangal ---> Warangal\n",
            ", ---> ,\n",
            "Telan ---> Telan\n",
            "It ---> It\n",
            "is ---> is\n",
            "in ---> in\n",
            "150 ---> 150\n",
            "acres ---> acre\n",
            ", ---> ,\n",
            "with ---> with\n",
            "both ---> both\n",
            "separate ---> separate\n",
            "hostel ---> hostel\n",
            "facilities ---> facility\n",
            "for ---> for\n",
            "boys ---> boy\n",
            "and ---> and\n",
            "girls ---> girl\n",
            ". ---> .\n",
            "There ---> There\n",
            "is ---> is\n",
            "a ---> a\n",
            "huge ---> huge\n",
            "central ---> central\n",
            "library ---> library\n",
            "along ---> along\n",
            "with ---> with\n",
            "Indias ---> Indias\n",
            "largest ---> largest\n",
            "Technology ---> Technology\n",
            "Business ---> Business\n",
            "Incubator ---> Incubator\n",
            "( ---> (\n",
            "TBI ---> TBI\n",
            ") ---> )\n",
            "in ---> in\n",
            "tier ---> tier\n",
            "2 ---> 2\n",
            "cities ---> city\n",
            ". ---> .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import RegexpStemmer\n",
        "regexp = RegexpStemmer('ing|e', min=4)\n",
        "words = word_tokenize(SRUniversity)\n",
        "for word in words:\n",
        "    print(word,\"--->\",regexp.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4L4yBXVxDKNZ",
        "outputId": "9d95ff33-18d1-48dd-e2d6-c7131d09e7da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The ---> The\n",
            "SR ---> SR\n",
            "University ---> Univrsity\n",
            "campus ---> campus\n",
            "is ---> is\n",
            "located ---> locatd\n",
            "in ---> in\n",
            "Ananthasagar ---> Ananthasagar\n",
            "village ---> villag\n",
            "of ---> of\n",
            "Hasanparthy ---> Hasanparthy\n",
            "Mandal ---> Mandal\n",
            "in ---> in\n",
            "Warangal ---> Warangal\n",
            ", ---> ,\n",
            "Telan ---> Tlan\n",
            "It ---> It\n",
            "is ---> is\n",
            "in ---> in\n",
            "150 ---> 150\n",
            "acres ---> acrs\n",
            ", ---> ,\n",
            "with ---> with\n",
            "both ---> both\n",
            "separate ---> sparat\n",
            "hostel ---> hostl\n",
            "facilities ---> facilitis\n",
            "for ---> for\n",
            "boys ---> boys\n",
            "and ---> and\n",
            "girls ---> girls\n",
            ". ---> .\n",
            "There ---> Thr\n",
            "is ---> is\n",
            "a ---> a\n",
            "huge ---> hug\n",
            "central ---> cntral\n",
            "library ---> library\n",
            "along ---> along\n",
            "with ---> with\n",
            "Indias ---> Indias\n",
            "largest ---> largst\n",
            "Technology ---> Tchnology\n",
            "Business ---> Businss\n",
            "Incubator ---> Incubator\n",
            "( ---> (\n",
            "TBI ---> TBI\n",
            ") ---> )\n",
            "in ---> in\n",
            "tier ---> tir\n",
            "2 ---> 2\n",
            "cities ---> citis\n",
            ". ---> .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import LancasterStemmer\n",
        "Lanc = LancasterStemmer()\n",
        "words = word_tokenize(SRUniversity)\n",
        "for word in words:\n",
        "    print(word,\"--->\",Lanc.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yLqS87W4DPwM",
        "outputId": "25c5f852-8ebf-4d89-bdfe-fe894c9f29a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The ---> the\n",
            "SR ---> sr\n",
            "University ---> univers\n",
            "campus ---> camp\n",
            "is ---> is\n",
            "located ---> loc\n",
            "in ---> in\n",
            "Ananthasagar ---> ananthasag\n",
            "village ---> vil\n",
            "of ---> of\n",
            "Hasanparthy ---> hasanparthy\n",
            "Mandal ---> mand\n",
            "in ---> in\n",
            "Warangal ---> warang\n",
            ", ---> ,\n",
            "Telan ---> tel\n",
            "It ---> it\n",
            "is ---> is\n",
            "in ---> in\n",
            "150 ---> 150\n",
            "acres ---> acr\n",
            ", ---> ,\n",
            "with ---> with\n",
            "both ---> both\n",
            "separate ---> sep\n",
            "hostel ---> hostel\n",
            "facilities ---> facil\n",
            "for ---> for\n",
            "boys ---> boy\n",
            "and ---> and\n",
            "girls ---> girl\n",
            ". ---> .\n",
            "There ---> ther\n",
            "is ---> is\n",
            "a ---> a\n",
            "huge ---> hug\n",
            "central ---> cent\n",
            "library ---> libr\n",
            "along ---> along\n",
            "with ---> with\n",
            "Indias ---> india\n",
            "largest ---> largest\n",
            "Technology ---> technolog\n",
            "Business ---> busy\n",
            "Incubator ---> incub\n",
            "( ---> (\n",
            "TBI ---> tbi\n",
            ") ---> )\n",
            "in ---> in\n",
            "tier ---> tier\n",
            "2 ---> 2\n",
            "cities ---> city\n",
            ". ---> .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PDF ASSIGNMENT:"
      ],
      "metadata": {
        "id": "-kglrQY5A_d5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"NLP models are transforming the world rapidly!\""
      ],
      "metadata": {
        "id": "QOsOqSX18tzr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1)IN WORD TOKENS :"
      ],
      "metadata": {
        "id": "_1hM--m182eJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "using nltk:"
      ],
      "metadata": {
        "id": "FvxLnDkc9rPk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Download tokenizer (run once)\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab') # Added to download the required resource\n",
        "\n",
        "text = \"NLP models are transforming the world rapidly!\"\n",
        "\n",
        "tokens = word_tokenize(text)\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NUWPilQ81ui",
        "outputId": "c9cf0bd1-4fc0-425b-f65b-4c1ac5811543"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['NLP', 'models', 'are', 'transforming', 'the', 'world', 'rapidly', '!']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "['NLP', 'models', 'are', 'transforming', 'the', 'world', 'rapidly', '!']\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKIQYZn59cjF",
        "outputId": "02eb53d5-f248-4812-c749-785283ba8cdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['NLP', 'models', 'are', 'transforming', 'the', 'world', 'rapidly', '!']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "using spacy\n"
      ],
      "metadata": {
        "id": "pbhDqkTV9k5v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "# Load English model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "text = \"NLP models are transforming the world rapidly!\"\n",
        "\n",
        "doc = nlp(text)\n",
        "tokens = [token.text for token in doc if not token.is_punct]\n",
        "\n",
        "print(tokens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pObdCON19nGi",
        "outputId": "82a68aa5-6e7f-45d0-d5f2-8c32c18ad06b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['NLP', 'models', 'are', 'transforming', 'the', 'world', 'rapidly']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2)STEMMED WORDS:\n"
      ],
      "metadata": {
        "id": "dFTSvO4l9t7J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "USING NLTK:"
      ],
      "metadata": {
        "id": "cIlwdAxC9zLC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "# Download tokenizer (run once)\n",
        "nltk.download('punkt')\n",
        "\n",
        "text = \"NLP models are transforming the world rapidly!\"\n",
        "\n",
        "# Tokenization\n",
        "tokens = word_tokenize(text)\n",
        "\n",
        "# Initialize stemmer\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "# Apply stemming (ignore punctuation)\n",
        "stemmed_words = [stemmer.stem(word) for word in tokens if word.isalpha()]\n",
        "\n",
        "print(stemmed_words)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXUEBHhV900R",
        "outputId": "9f0fde0d-9e5b-41b0-b408-6262c449f08d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['nlp', 'model', 'are', 'transform', 'the', 'world', 'rapidli']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3)Lemmatization :"
      ],
      "metadata": {
        "id": "h-XuEuyk-KY4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "# Load spaCy English model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "text = \"NLP models are transforming the world rapidly!\"\n",
        "\n",
        "# Process text\n",
        "doc = nlp(text)\n",
        "\n",
        "# Apply lemmatization (ignore punctuation)\n",
        "lemmatized_words = [token.lemma_ for token in doc if token.is_alpha]\n",
        "\n",
        "print(lemmatized_words)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "978uqfoi-S8q",
        "outputId": "12ae6963-4953-4e53-a653-9a3a9a9cc680"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['NLP', 'model', 'be', 'transform', 'the', 'world', 'rapidly']\n"
          ]
        }
      ]
    }
  ]
}